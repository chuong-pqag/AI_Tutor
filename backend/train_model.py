# File: backend/train_model.py
# (Báº¢N HOÃ€N CHá»ˆNH - ÄÃ£ sá»­a lá»—i import joblib vÃ  Ä‘Æ°á»ng dáº«n)

import joblib
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
from supabase import create_client
from dotenv import load_dotenv
import os

# --- Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN TUYá»†T Äá»I ---
# Láº¥y thÆ° má»¥c chá»©a file script hiá»‡n táº¡i (tá»©c lÃ  thÆ° má»¥c 'backend')
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))

# XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n file .env (náº±m á»Ÿ thÆ° má»¥c gá»‘c, tá»©c lÃ  cha cá»§a backend)
BASE_DIR = os.path.dirname(CURRENT_DIR)
ENV_PATH = os.path.join(BASE_DIR, '.env')

# Load .env tá»« Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i
load_dotenv(ENV_PATH)

SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i Ä‘á»ƒ lÆ°u model (lÆ°u ngay trong thÆ° má»¥c backend)
MODEL_PATH = os.path.join(CURRENT_DIR, 'model_recommender.pkl')


# --- HÃ€M Táº O TARGET (Y) Má»šI ---
def map_action_smart(row):
    """
    Táº¡o nhÃ£n (Y) dá»±a trÃªn Tá»¶ Lá»† % sÆ° pháº¡m chi tiáº¿t.
    """
    pct_biet = row.get('pct_biet', 0)
    pct_hieu = row.get('pct_hieu', 0)
    pct_van_dung = row.get('pct_van_dung', 0)
    pct_tong = row.get('pct_tong', 0)  # Äiá»ƒm tá»•ng thang 10

    # 1. ğŸŸ¥ Há»ŒC Láº I (Remediate): Náº¿u há»•ng kiáº¿n thá»©c ná»n táº£ng
    if (pct_biet < 0.5) or (pct_hieu < 0.5):
        return 0  # Remediate

    # 2. ğŸŸ© Há»ŒC TIáº¾P (Advance): Náº¿u lÃ m chá»§ cáº£ kiáº¿n thá»©c nÃ¢ng cao
    if (pct_tong >= 0.85) and (pct_van_dung >= 0.7):
        return 2  # Advance

    # 3. ğŸŸ¨ Ã”N Táº¬P (Review): CÃ¡c trÆ°á»ng há»£p cÃ²n láº¡i
    return 1  # Review


def calculate_percentages(df):
    """HÃ m helper Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c cá»™t tá»· lá»‡ % má»™t cÃ¡ch an toÃ n."""
    df['pct_biet'] = df.apply(lambda row: row['diem_biet'] / row['tong_diem_biet'] if row['tong_diem_biet'] > 0 else 0,
                              axis=1)
    df['pct_hieu'] = df.apply(lambda row: row['diem_hieu'] / row['tong_diem_hieu'] if row['tong_diem_hieu'] > 0 else 0,
                              axis=1)
    df['pct_van_dung'] = df.apply(
        lambda row: row['diem_van_dung'] / row['tong_diem_van_dung'] if row['tong_diem_van_dung'] > 0 else 0, axis=1)
    df['pct_tong'] = df['diem'] / 10.0
    return df


def load_data_from_supabase():
    """Táº£i dá»¯ liá»‡u HUáº¤N LUYá»†N ÄÃƒ ÄÆ¯á»¢C Lá»ŒC Sáº CH (Láº§n 2)."""

    # 1. Láº¥y dá»¯ liá»‡u káº¿t quáº£ (6 cá»™t Ä‘iá»ƒm VÃ€ loai_bai_tap)
    res_kq = supabase.table('ket_qua_test').select(
        'diem, lop, chu_de_id, bai_tap(loai_bai_tap),'
        'diem_biet, diem_hieu, diem_van_dung,'
        'tong_diem_biet, tong_diem_hieu, tong_diem_van_dung'
    ).execute()

    df_kq = pd.DataFrame(res_kq.data)
    if df_kq.empty:
        print("KhÃ´ng cÃ³ dá»¯ liá»‡u trong báº£ng 'ket_qua_test'.")
        return None

    # 2. Láº¥y dá»¯ liá»‡u chá»§ Ä‘á»
    res_cd = supabase.table('chu_de').select('id, mon_hoc').execute()
    df_cd = pd.DataFrame(res_cd.data)
    if df_cd.empty:
        print("KhÃ´ng cÃ³ dá»¯ liá»‡u trong báº£ng 'chu_de'.")
        return None

    # 3. Merge
    df_cd = df_cd.rename(columns={'id': 'chu_de_id'})
    df_kq['chu_de_id'] = df_kq['chu_de_id'].astype(str)
    df_cd['chu_de_id'] = df_cd['chu_de_id'].astype(str)

    df = pd.merge(df_kq, df_cd, on='chu_de_id', how='left')

    # 4. Xá»­ lÃ½ Dá»¯ liá»‡u
    df['loai_bai_tap'] = df['bai_tap'].apply(lambda x: x.get('loai_bai_tap') if isinstance(x, dict) else None)

    numeric_cols = [
        'diem', 'lop',
        'diem_biet', 'diem_hieu', 'diem_van_dung',
        'tong_diem_biet', 'tong_diem_hieu', 'tong_diem_van_dung'
    ]
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    df = df.dropna(subset=numeric_cols + ['mon_hoc', 'loai_bai_tap'])
    if df.empty:
        print("KhÃ´ng cÃ³ dá»¯ liá»‡u há»£p lá»‡ sau khi lÃ m sáº¡ch.")
        return None

    # 5. Lá»ŒC Dá»® LIá»†U HUáº¤N LUYá»†N
    # Chá»‰ láº¥y BÃ i Kiá»ƒm tra Chá»§ Ä‘á»
    df_train = df[df['loai_bai_tap'] == 'kiem_tra_chu_de'].copy()

    if df_train.empty:
        print("KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u 'kiem_tra_chu_de' nÃ o.")
        return None

    # Chá»‰ láº¥y dá»¯ liá»‡u Má»šI (cÃ³ tá»•ng Ä‘iá»ƒm > 0)
    df_train['tong_cac_muc_do'] = df_train['tong_diem_biet'] + df_train['tong_diem_hieu'] + df_train[
        'tong_diem_van_dung']
    df_train = df_train[df_train['tong_cac_muc_do'] > 0].copy()

    if df_train.empty:
        print("KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u huáº¥n luyá»‡n Má»šI (chÆ°a cÃ³ Ä‘iá»ƒm Hiá»ƒu/Váº­n dá»¥ng).")
        return None

    # 6. Táº¡o Features & Target
    df_train = calculate_percentages(df_train)
    y = df_train.apply(map_action_smart, axis=1)

    feature_cols = ['pct_biet', 'pct_hieu', 'pct_van_dung', 'lop', 'mon_hoc']
    X = df_train[feature_cols]

    print(f"Dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Ã£ lá»c: {len(X)} máº«u.")
    print("PhÃ¢n phá»‘i cÃ¡c hÃ nh Ä‘á»™ng (y) má»›i:")
    print(y.value_counts(normalize=True))

    return X, y


def train():
    """Huáº¥n luyá»‡n model (Pipeline) vÃ  lÆ°u láº¡i."""
    print("Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh huáº¥n luyá»‡n LÃµi AI Má»›i (Láº§n 2 - Tá»· lá»‡ %)...")
    data = load_data_from_supabase()

    if data is None:
        print('KhÃ´ng cÃ³ dá»¯ liá»‡u huáº¥n luyá»‡n há»£p lá»‡.')
        return

    X, y = data

    if len(X) < 5:  # Giáº£m ngÆ°á»¡ng kiá»ƒm tra Ä‘á»ƒ test nhanh
        print(f"Lá»—i: Chá»‰ cÃ³ {len(X)} máº«u dá»¯ liá»‡u. Cáº§n nhiá»u hÆ¡n.")
        return

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # --- Pipeline ---
    numeric_features = ['pct_biet', 'pct_hieu', 'pct_van_dung']
    numeric_transformer = StandardScaler()
    categorical_features = ['lop', 'mon_hoc']
    categorical_transformer = OneHotEncoder(handle_unknown='ignore')

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ])

    model = DecisionTreeClassifier(max_depth=10, random_state=42, class_weight='balanced')

    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', model)
    ])

    print(f"Huáº¥n luyá»‡n Pipeline vá»›i {len(X_train)} máº«u...")
    pipeline.fit(X_train, y_train)

    print("\n--- ÄÃ¡nh giÃ¡ Model trÃªn táº­p Test ---")
    if len(X_test) > 0:
        y_pred = pipeline.predict(X_test)
        # target_names cáº§n khá»›p vá»›i sá»‘ lÆ°á»£ng class thá»±c táº¿ trong y
        unique_classes = sorted(y.unique())
        target_names = []
        if 0 in unique_classes: target_names.append('Remediate (0)')
        if 1 in unique_classes: target_names.append('Review (1)')
        if 2 in unique_classes: target_names.append('Advance (2)')

        print(classification_report(y_test, y_pred, target_names=target_names))
    else:
        print("Táº­p test quÃ¡ nhá» Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.")

    # --- LÆ°u Model ---
    try:
        joblib.dump(pipeline, MODEL_PATH)
        print(f"\nâœ… ÄÃ£ lÆ°u Pipeline (Model Má»›i) thÃ nh cÃ´ng vÃ o: {MODEL_PATH}")
    except Exception as e:
        print(f"âŒ Lá»—i khi lÆ°u model: {e}")


if __name__ == '__main__':
    train()