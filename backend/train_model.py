# File: backend/train_model.py
# (N√ÇNG C·∫§P L√ïI AI L·∫¶N 2 - S·ª¨ D·ª§NG T·ª∂ L·ªÜ PH·∫¶N TRƒÇM %)

import joblib
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
from supabase import create_client
from dotenv import load_dotenv
import os

load_dotenv()
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

MODEL_PATH = 'backend/model_recommender.pkl'


# --- (QUAN TR·ªåNG) H√ÄM T·∫†O TARGET (Y) M·ªöI ---
def map_action_smart(row):
    """
    T·∫°o nh√£n (Y) d·ª±a tr√™n T·ª∂ L·ªÜ % s∆∞ ph·∫°m chi ti·∫øt.
    Quy t·∫Øc n√†y √°p d·ª•ng SAU KHI ƒë√£ t√≠nh to√°n pct_*.
    """
    pct_biet = row.get('pct_biet', 0)
    pct_hieu = row.get('pct_hieu', 0)
    pct_van_dung = row.get('pct_van_dung', 0)
    pct_tong = row.get('pct_tong', 0)  # ƒêi·ªÉm t·ªïng thang 10

    # 1. üü• H·ªåC L·∫†I (Remediate): N·∫øu h·ªïng ki·∫øn th·ª©c n·ªÅn t·∫£ng
    # (√Åp d·ª•ng ngay c·∫£ khi ƒëi·ªÉm t·ªïng cao)
    if (pct_biet < 0.5) or (pct_hieu < 0.5):
        return 0  # Remediate

    # 2. üü© H·ªåC TI·∫æP (Advance): N·∫øu l√†m ch·ªß c·∫£ ki·∫øn th·ª©c n√¢ng cao
    if (pct_tong >= 0.85) and (pct_van_dung >= 0.7):
        return 2  # Advance

    # 3. üü® √îN T·∫¨P (Review): C√°c tr∆∞·ªùng h·ª£p c√≤n l·∫°i
    # (V√≠ d·ª•: Bi·∫øt/Hi·ªÉu > 50% nh∆∞ng V·∫≠n d·ª•ng < 70%)
    return 1  # Review


def calculate_percentages(df):
    """H√†m helper ƒë·ªÉ t√≠nh to√°n c√°c c·ªôt t·ª∑ l·ªá % m·ªôt c√°ch an to√†n."""

    # T√≠nh to√°n an to√†n, tr√°nh chia cho 0
    df['pct_biet'] = df.apply(lambda row: row['diem_biet'] / row['tong_diem_biet'] if row['tong_diem_biet'] > 0 else 0,
                              axis=1)
    df['pct_hieu'] = df.apply(lambda row: row['diem_hieu'] / row['tong_diem_hieu'] if row['tong_diem_hieu'] > 0 else 0,
                              axis=1)
    df['pct_van_dung'] = df.apply(
        lambda row: row['diem_van_dung'] / row['tong_diem_van_dung'] if row['tong_diem_van_dung'] > 0 else 0, axis=1)

    # Chu·∫©n h√≥a ƒëi·ªÉm t·ªïng v·ªÅ thang 0-1 (t∆∞∆°ng t·ª± thang 10)
    df['pct_tong'] = df['diem'] / 10.0

    return df


def load_data_from_supabase():
    """T·∫£i d·ªØ li·ªáu HU·∫§N LUY·ªÜN ƒê√É ƒê∆Ø·ª¢C L·ªåC S·∫†CH (L·∫ßn 2)."""

    # 1. L·∫•y d·ªØ li·ªáu k·∫øt qu·∫£ (bao g·ªìm 6 c·ªôt ƒëi·ªÉm V√Ä loai_bai_tap)
    res_kq = supabase.table('ket_qua_test').select(
        'diem, lop, chu_de_id, bai_tap(loai_bai_tap),'
        'diem_biet, diem_hieu, diem_van_dung,'
        'tong_diem_biet, tong_diem_hieu, tong_diem_van_dung'
    ).execute()

    df_kq = pd.DataFrame(res_kq.data)
    if df_kq.empty:
        print("Kh√¥ng c√≥ d·ªØ li·ªáu trong b·∫£ng 'ket_qua_test'.")
        return None

    # 2. L·∫•y d·ªØ li·ªáu ch·ªß ƒë·ªÅ (ƒë·ªÉ l·∫•y 'mon_hoc')
    res_cd = supabase.table('chu_de').select('id, mon_hoc').execute()
    df_cd = pd.DataFrame(res_cd.data)
    if df_cd.empty:
        print("Kh√¥ng c√≥ d·ªØ li·ªáu trong b·∫£ng 'chu_de'.")
        return None

    # 3. Merge hai b·∫£ng
    df_cd = df_cd.rename(columns={'id': 'chu_de_id'})
    df_kq['chu_de_id'] = df_kq['chu_de_id'].astype(str)
    df_cd['chu_de_id'] = df_cd['chu_de_id'].astype(str)

    df = pd.merge(df_kq, df_cd, on='chu_de_id', how='left')

    # 4. X·ª≠ l√Ω D·ªØ li·ªáu (L√†m s·∫°ch)
    df['loai_bai_tap'] = df['bai_tap'].apply(lambda x: x.get('loai_bai_tap') if isinstance(x, dict) else None)

    # C√°c c·ªôt ƒëi·ªÉm th√¥
    numeric_cols = [
        'diem', 'lop',
        'diem_biet', 'diem_hieu', 'diem_van_dung',
        'tong_diem_biet', 'tong_diem_hieu', 'tong_diem_van_dung'
    ]
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    df = df.dropna(subset=numeric_cols + ['mon_hoc', 'loai_bai_tap'])
    if df.empty:
        print("Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l√†m s·∫°ch (b∆∞·ªõc 1).")
        return None

    # ===============================================
    # 5. (C·∫¨P NH·∫¨T) L·ªåC D·ªÆ LI·ªÜU HU·∫§N LUY·ªÜN
    # ===============================================

    # L·ªçc 1: Ch·ªâ l·∫•y B√†i Ki·ªÉm tra Ch·ªß ƒë·ªÅ (lo·∫°i b·ªè B√†i Luy·ªán t·∫≠p)
    df_train = df[df['loai_bai_tap'] == 'kiem_tra_chu_de'].copy()

    if df_train.empty:
        print("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu 'kiem_tra_chu_de' n√†o.")
        return None

    # L·ªçc 2: Ch·ªâ l·∫•y d·ªØ li·ªáu M·ªöI (n∆°i c√≥ d·ªØ li·ªáu ƒëi·ªÉm t·ªëi ƒëa)
    # (Lo·∫°i b·ªè 126 m·∫´u c≈© kh√¥ng c√≥ tong_diem_*)
    df_train['tong_cac_muc_do'] = df_train['tong_diem_biet'] + df_train['tong_diem_hieu'] + df_train[
        'tong_diem_van_dung']
    df_train = df_train[df_train['tong_cac_muc_do'] > 0].copy()

    if df_train.empty:
        print("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu hu·∫•n luy·ªán M·ªöI (ch∆∞a c√≥ ƒëi·ªÉm Hi·ªÉu/V·∫≠n d·ª•ng).")
        print("VUI L√íNG TH√äM C√ÇU H·ªéI HI·ªÇU/V·∫¨N D·ª§NG V√Ä CHO H·ªåC SINH L√ÄM B√ÄI.")
        return None

    # ===============================================

    # 6. T·∫°o Features (T·ª∑ l·ªá %)
    df_train = calculate_percentages(df_train)

    # 7. T·∫°o Target (Y) b·∫±ng quy t·∫Øc th√¥ng minh
    y = df_train.apply(map_action_smart, axis=1)

    # 8. T·∫°o Features (X)
    # (M·ªöI: D√πng c√°c c·ªôt % v√† c√°c c·ªôt danh m·ª•c)
    feature_cols = ['pct_biet', 'pct_hieu', 'pct_van_dung', 'lop', 'mon_hoc']
    X = df_train[feature_cols]

    print(f"D·ªØ li·ªáu hu·∫•n luy·ªán ƒë√£ l·ªçc: {len(X)} m·∫´u.")
    print("Ph√¢n ph·ªëi c√°c h√†nh ƒë·ªông (y) m·ªõi:")
    print(y.value_counts(normalize=True))

    return X, y


def train():
    """Hu·∫•n luy·ªán model (Pipeline) v√† l∆∞u l·∫°i."""
    print("B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán L√µi AI M·ªõi (L·∫ßn 2 - T·ª∑ l·ªá %)...")
    data = load_data_from_supabase()

    if data is None:
        print('Kh√¥ng c√≥ d·ªØ li·ªáu hu·∫•n luy·ªán h·ª£p l·ªá.')
        return

    X, y = data

    if len(X) < 10:
        print(f"L·ªói: Ch·ªâ c√≥ {len(X)} m·∫´u d·ªØ li·ªáu h·ª£p l·ªá. C·∫ßn nhi·ªÅu d·ªØ li·ªáu h∆°n ƒë·ªÉ hu·∫•n luy·ªán.")
        return

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # --- 1. ƒê·ªãnh nghƒ©a Preprocessor (C·∫¨P NH·∫¨T) ---

    # C√°c c·ªôt t·ª∑ l·ªá % (ƒë√£ ·ªü thang 0-1)
    numeric_features = ['pct_biet', 'pct_hieu', 'pct_van_dung']
    numeric_transformer = StandardScaler()  # V·∫´n scale ƒë·ªÉ chu·∫©n h√≥a

    # C√°c c·ªôt danh m·ª•c
    categorical_features = ['lop', 'mon_hoc']
    categorical_transformer = OneHotEncoder(handle_unknown='ignore')

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ])

    # --- 2. ƒê·ªãnh nghƒ©a Model (Gi·ªØ nguy√™n) ---
    model = DecisionTreeClassifier(max_depth=10, random_state=42, class_weight='balanced')

    # --- 3. T·∫°o Pipeline (Gi·ªØ nguy√™n) ---
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', model)
    ])

    print(f"Hu·∫•n luy·ªán Pipeline (DecisionTree) v·ªõi {len(X_train)} m·∫´u...")
    pipeline.fit(X_train, y_train)

    # --- 4. ƒê√°nh gi√° Model (Gi·ªØ nguy√™n) ---
    print("\n--- ƒê√°nh gi√° Model tr√™n t·∫≠p Test ---")
    y_pred = pipeline.predict(X_test)
    print(classification_report(y_test, y_pred, target_names=['Remediate (0)', 'Review (1)', 'Advance (2)']))

    # --- 5. L∆∞u Model (Gi·ªØ nguy√™n) ---
    try:
        joblib.dump(pipeline, MODEL_PATH)
        print(f"\nƒê√£ l∆∞u Pipeline (Model M·ªõi) v√†o: {MODEL_PATH}")
    except Exception as e:
        print(f"L·ªói khi l∆∞u model: {e}")


if __name__ == '__main__':
    train()